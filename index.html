<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>GRaM Workshop | Geometry-grounded Representation Learning and Generative Modeling</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="GRaM Workshop" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Geometry-grounded Representation Learning and Generative Modeling" />
<meta property="og:description" content="Geometry-grounded Representation Learning and Generative Modeling" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="GRaM Workshop" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="GRaM Workshop" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Geometry-grounded Representation Learning and Generative Modeling","headline":"GRaM Workshop","name":"GRaM Workshop","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/bannerimg.png"}},"url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=bed78daefaf5230b3737a905659be89397b5114f">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->


<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">GRaM Workshop @ ICML 2024</h1>
      <h2 class="project-tagline">ELLIS Workshop on Geometry-grounded Representation Learning and Generative Modeling</h2>
      
        <a href="./index.html" class="btn">GRaM</a>
        <a href="./cfp.html" class="btn">Call for papers</a>
        <a href="./faq.html", class="btn">FAQs </a>
	<a href="./speakers.html", class="btn">Speakers</a>
	<a href="./schedule.html", class="btn">Schedule</a>
    </header>
    <div style="display: flex; justify-content: center; align-items: center; margin-top: 20px;">
      <img src="assets/img/ICML-logo.svg" alt="ICML Logo" style="width: 200px; margin-right: 100px;">
        <img src="assets/img/20230223_ELLIS_Logo_RGB_hor_subline.png" alt="ELLIS Logo" style="width: 380px; margin-right: 100px;">
        <img src="assets/img/elise .png" alt="ELISE Logo" style="width: 150px; margin-right: 100px;">
        <img src="assets/img/EN-Funded by the EU-POS.png" alt="EU Logo" style="width: 280px;">
      </div>
    <main id="content" class="main-content" role="main">


	   
      
      <h2 id="motivation">Accepted submissions</h2>

      <p><span style="color: rgb(255, 136, 0);">Accepted papers</span> in both the extended abstract and proceedings track of GRaM can be found <a href="https://openreview.net/group?id=ICML.cc/2024/Workshop/GRaM">here!</a></p>

      <p><span style="color: rgb(255, 136, 0);">Accepted blogposts and tutorials</span> can be found <a href="https://gram-blogposts.github.io/">here!</a></p>

      <h2 id="motivation">Motivation</h2>

      <p>
        By recognizing that nearly all data is rooted in our physical world, and thus inherently grounded in geometry and physics, it becomes evident that representation learning should preserve this grounding in order to remain meaningful. For example, preserving group transformation laws and symmetries through equivariant layers is crucial in domains such as computational physics, chemistry, robotics, and medical imaging, and leads to effective and generalizable architectures and improved data efficiency. Similarly, in generative models applied to non-Euclidean data spaces, maintaining the manifold structure is essential in order to obtain meaningful samples. Therefore, this workshop focuses on the principle of <em>grounding in geometry</em>, which we define as follows:
      </p>

      <blockquote>
        <p><span style="color: rgb(255, 136, 0);">A representation, method, or theory is grounded in geometry if it can be amenable to geometric reasoning, that is, it abides by the mathematics of geometry and physics.</span></p>
      </blockquote>

      <h2 id="topics">Topics</h2>
      <p>
        We solicit submissions that present theoretical research, methodologies, applications, insightful analysis, and even open problems, within the following topics (list not exhaustive):
      </p>
      <ul>
        <li><strong>Structure-preserving learning</strong>
          <ul>
            <li><span style="color: rgb(255, 136, 0);">Preservation of symmetries</span>; E.g., through equivariant operators.</li>
            <li><span style="color: rgb(255, 136, 0);">Dynamical systems on manifolds</span>; Representation learning and generative modeling using ordinary, stochastic, and differential equations (ODEs, SDEs, PDEs) on manifolds. </li>
            <li><span style="color: rgb(255, 136, 0);">Computing with geometric representations</span>; Such as the processing of multi-vectors using geometric algebra, steerable vectors using Clebsch-Gordan products, and hyperbolic features using Fr√©chet means.</li>
          </ul>
        </li>
        <li><strong>Structure-inducing learning</strong>
          <ul>
            <li><span style="color: rgb(255, 136, 0);">Self-supervised learning</span>; E.g., learning to embed data in geometric latent spaces through (geodesic) distance-based similarity metrics.</li>
            <li><span style="color: rgb(255, 136, 0);">Geometric priors</span>; E.g., soft constraints on model weights.</li>
            <li><span style="color: rgb(255, 136, 0);">Physics-Informed Neural Networks</span>; E.g., inducing the structure of established physical and geometric laws into neural networks through dedicated losses.</li>
          </ul>
        </li>
        <li><strong>Generative modeling and density estimation</strong>
          <ul>
            <li><span style="color: rgb(255, 136, 0);">Geometric latent variable models</span>; I.e., the use of latent variables that live in a manifold.</li>
            <li><span style="color: rgb(255, 136, 0);">New Methods</span>; And adaptations of methods capable of:</li>
            <li><span style="color: rgb(255, 136, 0);">Generating geometric objects</span>; E.g., generating atomic point clouds or shapes.</li>
            <li><span style="color: rgb(255, 136, 0);">Generating fields over manifolds</span>; E.g., generating vector fields or spherical signals.</li>
          </ul>
        </li>
        <li><strong>Grounding in theory</strong>
          <ul>
            <li><span style="color: rgb(255, 136, 0);">Theoretical frameworks</span>; Unifying analyses and formulations that provide a generalizing perspective on deep learning paradigms.</li>
            <li><span style="color: rgb(255, 136, 0);">Open problems</span>; Identifying and addressing unresolved questions and challenges that lie at the intersection of geometry and learning</li>
          </ul>
        </li>
      </ul>


      <h2 id="cfp">Call for papers</h2>
      <p>The workshop solicits submissions to the</p>
      <ul>
        <li><strong>Proceedings track</strong>: 8 page paper submissions (excluding appendices and references). Submissions will be peer-reviewed. Accepted papers will be published in PMLR as part of our workshop proceedings.</li>
        <li><strong>Extended abstract track</strong>: 4 page paper submissions (excluding appendices and references). Submissions will be peer-reviewed. Accepted papers can be viewed on openreview.</li>
	<li><strong>Blogpost track</strong>: blog posts that have tutorial value and act as explainers for (previously) published papers or important topics in the field. In this track, we further encourage blog posts that present opinion pieces, open problems,etc in provided markdown format. Submissions will be peer-reviewed and accepted submissions will be hosted on GRaM wesbite.</li>
	        <li><strong>Tutorial track </strong>: Tutorials with easy-to-use and understand code for topics of important to GRaM audience submitted as a collab file. Submissions will be peer-reviewed and accepted submissions will be hosted on GRaM website.</li>
		<li><strong>TAG challenge</strong>: We team up with <a href="https://www.tagds.com/">TAG</a> and host a <em>ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain</em> challenge.</li>
      </ul>
  
      <h2>Reviewing for GRaM</h2>
      <p>If you would like to review for our workshop, please signup <a href="https://docs.google.com/forms/d/e/1FAIpQLSfCEkzvuCyRFTSZQZ97zvohLddXTh8vbd9gzki_C5NRfFH50A/viewform?usp=sf_link">here</a>.</p>
<h2>Contact</h2>
      <p> If you have any questions, please feel free to email us at <a href="mailto:organizers@gram-workshop.org">organizers AT gram-workshop DOT org </a> </p>
      
      
      
      <h2 id="organizers">Organizers</h2>

<div class="wide-container">
  <div class="organizers-container">
    <div class="organizer big-organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/sharvaree_vadgama.jpg" alt="Sharvaree Vadgama" class="organizer-photo big-photo">
        <strong>Sharvaree Vadgama</strong>
      </div>
      <div class="organizer-bio">
        <p>Sharvaree Vadgama is a PhD student at Amsterdam Machine Learning Lab, University of Amsterdam. Her work is focused on learning representations primarily in the intersection of geometric deep learning and generative modeling. She was a co-organizer of Generative Modeling Summer School (GeMSS) 2023 as well as a co-organizer of Women in AI meetups (Amsterdam chapter).</p>
      </div>
    </div>
    <div class="organizer big-organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/erik_bekkers.jpg" alt="Erik Bekkers" class="organizer-photo big-photo">
        <strong>Erik Bekkers</strong>
      </div>
      <div class="organizer-bio">
        <p>Erik Bekkers is an assistant professor at the Machine Learning Lab of the University of Amsterdam (AMLab, UvA) and an ELLIS Scholar in the program on Geometric Deep Learning. His research is equivariant deep learning and computational and representation efficiency through sparse, adaptive, and geometric learning mechanisms. He has organized several international workshops and conference sessions (e.g., GeoMedIA'22, GSI '21 and '23, two ELLIS workshops on GDL). He chairs the board of examiners for the Master AI at UvA. Erik received a VENI personal research grant (Dutch Research Council) and the Young Scientist Award at MICCAI 2018.</p>
      </div>
    </div>
  </div>

  <div class="organizers-container">
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/alison_pouplin.jpg" alt="Alison Pouplin" class="organizer-photo">
        <strong>Alison Pouplin</strong>
      </div>
      <div class="organizer-bio">
        <p>Alison Pouplin is a postdoctoral researcher at the Finnish Center of AI. Her current research interests involve geometric deep learning and generative modeling applied to drug discovery. She defended her PhD on differential geometric approaches to machine learning.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/hannah_lawrence.jpg" alt="Hannah Lawrence" class="organizer-photo">
        <strong>Hannah Lawrence</strong>
      </div>
      <div class="organizer-bio">
        <p>Hannah Lawrence is a PhD student at the Massachusetts Institute of Technology. Her research centers on symmetries in deep learning, aiming to both establish theoretical foundations and efficiently exploit equivariance in (often scientific) applications. She is also a co-founder of the Boston Symmetry Group, which organizes an annual workshop for Boston-area researchers in equivariance. She is supported by the Hertz Foundation and the National Science Foundation.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/oumar_kaba.jpg" alt="S√©kou-Oumar Kaba" class="organizer-photo">
        <strong>S√©kou-Oumar Kaba</strong>
      </div>
      <div class="organizer-bio">
        <p>S√©kou-Oumar Kaba is a PhD student at McGill University and Mila, the Quebec AI institute. His interests are at the intersection of physics and deep learning, with a focus on symmetry and geometric inductive biases. In parallel, he also works on applications of machine learning to material science. He is a co-organizer of the Mila Quantum and AI meetups. He is a recipient of the DeepMind PhD scholarship.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/robin_walters.jpg" alt="Robin Walters" class="organizer-photo">
        <strong>Robin Walters</strong>
      </div>
      <div class="organizer-bio">
        <p>Robin Walters is an assistant professor in the Khoury College of Computer Sciences at Northeastern University, where he leads the Geometric Learning Lab. Robin‚Äôs research seeks to develop a fundamental understanding of the role symmetry plays in deep learning and to exploit this to improve the generalization and data efficiency of deep learning methods. This includes designing equivariant neural networks, symmetry discovery methods, and creating a theory of symmetry for model parameters. He has applied these methods to improve models in domains with complex dynamics including climate science, transportation, and robotics.</p>
      </div>
    </div>
  </div>

  <div class="organizers-container">
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/jakub_tomzak.jpg" alt="Jakub Tomczak" class="organizer-photo">
        <strong>Jakub Tomczak</strong>
      </div>
      <div class="organizer-bio">
        <p>Jakub M. Tomczak is an associate professor and the PI of the Generative AI group at the Eindhoven University of Technology (TU/e). His main research interests include deep generative modeling, deep learning, and Bayesian inference, with applications to image/text processing, Life Sciences, and Molecular Sciences. He serves as an action editor of "Transactions of Machine Learning Research", and an area chair of major AI conferences (e.g., NeurIPS, ICML, AISTATS). He was a co-organizer of the Neurosymbolic and Generative Models (NeSy-GeMs) Workshop at ICLR 2023. He will serve as a program chair of NeurIPS 2024. He is the author of the book entitled "Deep Generative Modeling", the first comprehensive book on Generative AI. He is also the founder of Amsterdam AI Solutions.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/stefanie_jegelka.jpg" alt="Stefanie Jegelka" class="organizer-photo">
        <strong>Stefanie Jegelka</strong>
      </div>
      <div class="organizer-bio">
        <p>Stefanie Jegelka is an Associate Professor (on leave) at MIT EECS, and a Humboldt Professor at TU Munich. At MIT, she is a member of CSAIL, IDSS, and the Center for Statistics and Machine Learning. Before that, she was a postdoc in the AMPlab and computer vision group at UC Berkeley. Her research is in algorithmic machine learning and spans modeling, optimization algorithms, theory, and applications. In particular, her team has been working on exploiting mathematical structure for discrete and combinatorial machine learning problems, for robustness, and for scaling machine learning algorithms.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/henry_kvinge.jpeg" alt="Henry Kvinge" class="organizer-photo">
        <strong>Henry Kvinge</strong>
      </div>
      <div class="organizer-bio">
        <p>Henry Kvinge is a mathematician and machine learning researcher at Pacific Northwest National Lab and an Affiliate Assistant Professor in the University of Washington Mathematics Department. His research interests include representation learning, improving the robustness of deep learning models, and applications of topology, algebra, and geometry to machine learning and data science. He also works on applying machine learning to materials science. Henry organizes the 'Pacific Northwest Seminar on Topology, Algebra, and Geometry in Data Science' and is one of the founding organizers of the Topology, Algebra, and Geometry in Data Science series. His work has been featured in several articles, including recent papers on hidden activations in Stable Diffusion and the use of AI in advanced manufacturing processes.</p>
      </div>
    </div>
    <div class="organizer">
      <div class="organizer-header">
        <img src="assets/img/bio/tegan_emerson.jpg" alt="Tegan Emerson" class="organizer-photo">
        <strong>Tegan Emerson</strong>
      </div>
      <div class="organizer-bio">
        <p>Tegan Emerson received her PhD in Mathematics from Colorado State University. She was a Jerome and Isabella Karle Distinguished Scholar Fellow in optical sciences at the Naval Research Laboratory from 2017-2019. In 2014 she had the honor of being a member of the American delegation at the Heidelberg Laureate Forum. Dr. Emerson is now a Senior Data Scientist and Team Leader in the Data Sciences and Analytics Group at Pacific Northwest Laboratory. In addition to her role at Pacific Northwest National Laboratories, Dr. Emerson also holds Joint Appointments as Affiliate Faculty in the Departments of Mathematics at Colorado State University and the University of Texas, El Paso. Her research interests include geometric and topological data analysis, dimensionality reduction, algorithms for image processing and materials science, deep learning, and optimization.</p>
      </div>
    </div>
  </div>

  <div class="organizers-container">
    <div class="organizer-placeholder"></div> <!-- Placeholder to maintain the layout -->
    <div class="organizer-placeholder"></div> <!-- Placeholder to maintain the layout -->
  </div>
</div>


      <!-- <footer class="site-footer"> -->
        
          <!-- <span class="site-footer-owner"><a href="https://github.com/ebekkers/website-testing">website-testing</a> is maintained by <a href="https://github.com/ebekkers">ebekkers</a>.</span> -->
        
        <!-- <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span> -->
      <!-- </footer> -->


    </main>
  </body>
</html>
